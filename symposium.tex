\def\paper{\thesisOnly{chapter}\paperOnly{paper}}
\section{Introduction}

Capturing groups allow programmers to extract substrings matched by parts of a regular expression.
For example, the regex |"A(B)?"| matches both |"A"| and |"AB"|.
In the first case, the capturing group is empty, and in the second case, the capturing group contains |"B"|.

The Scala standard library contains a package to manipulate regular expressions.
This package is based on Java's implementation, and thus benefits from the high performance of the JVM's regex engine.
The Scala implementation innovates in its presentation: it improves upon Java's solution by providing an ergonomic API based on pattern matching that is both elegant and concise.
The package's documentation starts with the following example:

\regexDocumentation

\noindent
The extractor pattern, |case date(y,m,d)|, replaces the need for manually indexing into the regular expression's capturing groups, and shields users from off-by-one error.

While the syntax used in this example would undoubtedly make some non-Scala programmers envious, its type safety leaves much to be desired.
First of all, the \emph{number} of variable bindings in the extractor is entirely opaque to Scala's type system, and left to the discretion of the programmer.
Furthermore, the values that come out of capturing groups can be null (when using optional captures) and thus require an additional layer of validation.
Those shortcomings might appear benign on small examples, but can easily turn into bugs when dealing with a large-scale codebase.

In this \paper, we propose a new design for Scala's regular expression library which provides a type-safe and null-safe mechanism for capturing group extraction.
Our design makes extensive use of match types\paperOnly{~\citep{blanvillain2022type}, Scala~3's new feature for type-level programming,} to statically analyze regular expressions during type checking.
We build our interface to mimic Scala's original regular expression API so that Scala programmers can use it as a drop-in replacement and enjoy the additional safety with minimal migration costs.

This \paper is structured as follows.
In \Cref{sec:background}, we give an introduction to match types and generic tuples, two recent additions to Scala's type system which we rely on in our implementation.
In \Cref{sec:architecture},~\ref{sec:type-level} and~\ref{sec:term-level}, we present our library for type-safe regular expressions.
In \Cref{sec:evaluation}, we evaluate the performance of our implementation in terms of compilation times and execution times.
In \Cref{sec:related}, we discuss related work.
We conclude the \paper in \Cref{sec:conclusion}.

\thesisOnly{
The source code of our implementation is available online\footnote{\texttt{https://github.com/OlivierBlanvillain/regsafe}} under the MIT licence.
}
\paperOnly{
The source code of our implementation is available online\footnote{This URL is hidden for the purpose of the double-blind review process.} under the MIT licence.
}

\section{Background}
\label{sec:background}

In this section, we give a brief introduction to two recent additions to Scala's type system: match types and generic tuples.
Our regular expression library makes extensive use of those two features to enable type-safe and null-safe capturing group extraction.

\subsection{Match Types}

Match types provide first-class support for type-level computations in the form of pattern matching on types:

\elemExample
% type Elem[X] = X match
%   case String => Char
%   case Array[t] => Elem[t]
%   case Any => X

\noindent
This example defines a type |Elem| parametrized by one type parameter |X|.
The right-hand side is defined in terms of a match on that type parameter -- a match type.
A match type reduces to one of its right-hand sides, depending on the type of its scrutinee.
For example, the above type reduces as follows:

\begin{lstlisting}
Elem[String] =:= Char
Elem[Int] =:= Int
Elem[Array[Int]] =:= Int
\end{lstlisting}

\noindent
To reduce a match type, the scrutinee is compared to each pattern, one after the other, using subtyping.
For example, although |String| is a subtype of both |String| and |Any|, the |Elem[String]| type reduces to |Char| because the corresponding case appears first.

\subsection{Generic Tuples}
\label{subsec:generic-tuples}

Scala's tuples were originally defined as plain old data types.
In Scala~3, tuples got enhanced with a generic representation~\citep{bazzucchi2021tuples}, similar to heterogeneous lists~\citep{kiselyov2004strongly}.
This representation uses two types, |EmptyTuple| and |*:|, to describe tuples in a list-like fashion.
The compiler treats those new types and the traditional class-based representation of tuples interchangeably.
A 2-tuple of integers, for example, has two equivalent representations:

\begin{lstlisting}
(Int, Int) =:= Int *: Int *: EmptyTuple
\end{lstlisting}

\noindent
This new tuple representation is especially useful at the type level, where it allows programmers to manipulate tuples recursively.
For example, the following match type reverses the order of a tuple's elements:

\tupleReverseA
\vspace{-3pt}
\tupleReverseB

\section{Architecture}
\label{sec:architecture}

We present our library for type-safe regular expressions in terms of 3 components:

\begin{enumerate}
  \item The type-level capturing group analysis, which uses match types to inspect the user-provided regular expression and compute tuple representation of the expression's capturing groups.
  This component takes the form of a parametric type called |Compile|, which we present in \Cref{sec:type-level}.

  \item The runtime capturing group processing component, which extracts and sanitizes the output of the regex engine, in accordance with the previously computed type-level representation.
  This component takes the form of a function called |transform|, which we present in \Cref{sec:term-level}.

  \item The user interface, which ties everything together to compile, execute, and extract the results of a regular expression, while providing a type-safe and null-safe experience.
\end{enumerate}

We begin our presentation with the user interface, which takes the form of a relatively simple Scala class and companion object:

\regexUserLevel

The |apply| method is the entry point of our library.
It takes a regular expression and returns an instance of |Regex|.
Instead of directly accepting a |String| argument, that method takes a type parameter, |R|, which will be inferred by the compiler, and allows us to get our hands on a type-level instance of the regular expression's string (the |Singleton| bound is necessary to guide Scala's type inference).
We use that type-level string to instantiate the |Compile| type, which is our type-level analysis component.

The implementation of the |Regex| class is straightforward.
Similar to its standard library counterpart, that class uses an instance of |java.util.regex.Pattern| to match the given input against the given regular expression, and to extract the content of the capturing groups when the matching succeeds.
These operations happen within the |unapply| method, which is the way to define custom pattern matching extractors in Scala \citep{emir2007matching}.

The main difference between Scala's original |Regex| implementation and ours lies in the signature of |unapply|, which determines the nature of pattern matching extraction performed by that method.
In our implementation, we instantiate the type |P| to a tuple and use that type in the result type of |unapply| to tell the compiler that a successful matching consists of exactly $n$ capturing groups, where $n$ is the tuple's arity.
Furthermore, the type of those groups corresponds to the type of the tuple elements.
This allows us to enrich the results of Java's regex engine by wrapping nullable values into options.
Our implementation performs this wrapping via the |transform| method, which is our runtime processing component.
As a result, our implementation never returns null values and removes the null-checking burden from the user.

For instance, in the following example usage of our library, we use a regular expression with an optional capturing group to extract the integral and fractional parts of a rational number:

\regexRational

\noindent
Here, we instantiate |Regex|'s type parameter to |P = (String,| |Option[String])|, which we then use in |unapply|'s result type to obtain a precise representation of the regex's capturing groups.
The resulting code is type-safe: if we change the pattern to omit the option unpacking (replacing |Some(f)| by |f|), the compiler would raise a type error on the call to |.size| (size is defined on strings but not options).

In the following section, we explain our technique to analyze regular expressions and statically compute a type-level representation of the regex's capturing groups (|P| in the example above).

\section{Type-Level}
\label{sec:type-level}

The purpose of our type-level component is two-fold:

\begin{enumerate}
  \item Identify the capturing groups of a regular expression.
  \item Determine which of those capturing groups are optional, that is, whether or not the regex engine could possibly assign null values for each of those groups.
\end{enumerate}

\noindent
The result of that type-level computation takes the form of a Scala tuple with |String| and |Option[String]| elements, depending on the nullability analysis.

We present our implementation incrementally, starting from a simple but incomplete solution, and progressively building up towards our final solution.

\subsection{Capturing Group Identification}

The first version of our type-level program is limited to capturing group identification.
The implementation is straightforward, it iterates through the regex's characters and accumulates a |String| type for every opening parenthesis:

\regexFirstIteration

\noindent
The |Length| and |CharAt| types (from |ops.string|) are special-cased by the compiler: when their first argument is a known string literal, the compiler evaluates those types via their corresponding term-level implementation.
Similarly, the |+| type (from |ops.int|) allows us to manipulate integers just like we would at the term level.
The |EmptyTuple| and |*:| types are Scala~3's new generic representation of tuples, presented in \Cref{subsec:generic-tuples}.

\subsection{Out-Of-Bound Errors}

Attentive readers might have noticed that our handling of backslash, regex's escape character, might result in off-by-one errors.
Indeed, the |Loop| type terminates when |Lo = Hi|, but increases |Lo| by 2 to skip over escaped characters.

Rest assured, this is not an oversight!
Regular expressions with trailing backslashes are invalid and result in runtime crashes (reported as an "unexpected internal error").
Even though detecting these types of errors at compile time is out of the scope of our library, doing so is still desirable.
If we invoke |Compile| on a regular expression with a trailing backslash, the compiler will run into a call to |charAt| with an out of bounds argument, catch the corresponding exception and report it as a compilation error, which is certainly better reporting that same error at run-time.

\subsection{Non-Capturing Groups}
\label{subsec:non-capturing-groups}

Our first implementation of |Compile| treats every opening parenthesis as the start of a capturing group, which does not honor the syntax of Java's regular expression.
Indeed, Java also supports several other special constructs that start with an opening parenthesis, for instance:

\begin{itemize}
  \item non-capturing groups, |(?:X)|,
  \item lookaheads, |(?=X)| and |(?!X)|,
  \item lookbehinds, |(?<=X)| and |(?<!X)|.
\end{itemize}

\noindent
To correctly identify capturing groups (which can be either named, |(?<name>X)|, or unnamed, |(X)|), we must differentiate them from other special constructs.
Our second implementation (omitted) uses the following |IsCapturing| predicate type to rule out non-capturing groups:

\regexIsCapturing

\noindent
Similar to our handling of backslash characters, this implementation intentionally does not prevent out-of-bounds errors, since these errors correspond to ill-formed regular expressions.

\subsection{Nullability Analysis}

Establishing the nullability of capturing groups is more complicated than it sounds.
At first glance, it seems that this is simply a matter of looking for regex quantifiers in suffix position%
\footnote{
For brevity, our presentation does not account for the regex alternative operator, which also influences the nullability of capturing groups and can appear in both prefix and suffix positions.
Similarly, we omit handling the "at least $n$ times" quantifiers which can lead to nullable capturing groups (when $n=0$).
Our implementation accounts for both operators.
}.
For instance, in the following naive implementation of |IsNullable|, we look for the first closing parenthesis and inspect the following characters to determine if a capturing group is nullable:

\regexNaiveIsNullable

\noindent
Unfortunately, this naive solution does not handle regular expressions with nested capturing groups.
For example, in |"(A(B)?)"|, that solution incorrectly labels the first group as optional.
To overcome this problem, we update our solution to keep track of the number of opening and closing parentheses (|Lvl|), which allows us to differentiate closing parentheses of inner and outer groups%
\footnote{
For simplicity, our presentation treats all non-escaped parentheses as capturing group delimiters.
Our implementation also takes \lstinline!\\Q...\\E! quotations into account and ignores parentheses that appear in character classes.
}:

\regexIsNullable

Nested capturing groups bring another complication to the nullability analysis, which is caused by the interaction between inner and outer groups.
When an outer group is deemed optional, this overrides the nullability of all its inner groups, which also become optional.
For instance, in |"(A(B))?"|, both the first (|A(B)|) and the second (|B|) capturing group are optional.

We handle nested groups by updating our algorithm to operate in two different modes while iterating through the regex's characters.
Our algorithm can either be outside of an optional group (|Opt=0|), in which case it computes nullability of newly encountered groups via |IsNullable|, or inside an optional group (|Opt>0|), in which case it treats every group as nullable.

With this latest improvement, we advance our implementation to its final iteration (we omit usages of |IsCapturing|, from \Cref{subsec:non-capturing-groups}, for brevity):

\regexLastIteration

This concludes the development of our nullability analysis and completes our presentation of the type-level component of our library.
Despite the scarcity of Scala's standard library at the type level, we managed to achieve our ends while keeping our implementation relatively concise and, hopefully, understandable.
In its final iteration, our capturing group analysis is, to the best of our knowledge, on par with Java's implementation of regular expression.

\section{Term-Level}
\label{sec:term-level}

The runtime component of our library is in charge of sanitizing and packaging the results of regular expression matchings.
Concretely, this component's job consists of transforming the string array that comes out of the regex engine into an appropriately sized tuple and wrapping the nullable elements in options.
That transformation must conform to the representation computed at the type level.

In Scala, all type parameters are erased, which leads to some friction when wanting to write programs whose execution \emph{depends} on types, such as in the problem at hand. In this section, we propose two different solutions to that problem.

\begin{enumerate}
  \item In \Cref{subsec:we-ain-t-need-no-dependent-types}, we proceed by sheer force of code duplication: we translate the entirety of our type-level algorithm into term-level functions and use a cast to correlate the two.

  \item In \Cref{subsec:implicit-based-extractor-synthesis}, we show how to use implicits to perform type-directed code synthesis: we use the output of our type-level analysis as an input of implicit search to generate a type-specialized capturing group sanitizer.
\end{enumerate}

\subsection{We Don't Need No Dependent Types!}
\label{subsec:we-ain-t-need-no-dependent-types}

The first implementation of our runtime component duplicates the type-level definitions presented in the previous section to compute a list of sanitizing functions that correspond to the given regex's capturing groups.
In a nutshell, instead of accumulating |String| and |Option[String]| in a type, we accumulate identity functions and eta-expansions of the option constructor in a list:

\regexTermLvlLoop

\noindent
After having computed those functions, we do a pointwise application with the raw output of the regex engine, package the result into a tuple, \emph{et voilà!}

\regexTransform

This solution has the benefit of being conceptually simple.
We needed to write an implementation that conforms to our type-level program, and this is literally what we did, by duplicating that program and using an unsafe cast to convince the compiler of our good intentions.

The first alternative that comes to mind is perhaps to turn ourselves to a dependently typed language with support for type- and term-level polymorphism.
Using a language with shared term and type syntax would allow us to write our analysis generically, and derive two programs from it, one for each level.

In principle, Scala~3's type inference should be able to solve half of that problem with its ability to correlate match types and match expressions\paperOnly{~\citep[§ 2.1]{blanvillain2022type}}.%
\thesisOnly{
In \Cref{subsec:a-lightweight-form-of-dependent-typing}, we show an example of that ability, where the compiler type checks a small program using a match type.
}%
In our case, this mechanism should allow us to get rid of the unsafe cast but does not address the problem of code duplication.
In practice, at the time of writing, this solution does not play well with predefined types from the standard library: the compiler lacks the knowledge necessary to correlate predefined types with their term-level counterpart.
For instance, the compiler does not recognize |CharAt["hello", 0]| as a valid type for the |"hello".charAt(0)|.

In the long run, it would be interesting to investigate extending Scala with a "precise" mode of type inference, that would automatically infer match types and singleton types, whenever possible.
\thesisOnly{
In \Cref{chap:generalizing-singleton-types}, we demonstrated the feasibility of this approach by generalizing Scala's singleton types.
A promising avenue would be to revisit that line of work with the less ambitious goal of improving Scala's type inference.
}

\subsection{Implicit-Based Extractor Synthesis}
\label{subsec:implicit-based-extractor-synthesis}

The second version of our runtime component takes a completely different approach.
Instead of analyzing regular expressions at run-time, we use implicit resolution to \emph{synthesize} a type-specialized runtime, based on the results of our type-level analysis.
That synthesis is type-directed: it generates a single-purpose program that sanitizes the output of the regex engine by following the shape of the tuple type computed at the type level.

Our implementation consists of one type class, |Sanitizer|, and three implicit definitions, which will guide the compiler into generating the correct |Sanitizer[T]|, for any tuple |T| with |String| and |Option[String]| elements (here, |T| is the result of our type-level analysis).
The |Sanitizer| type class defines a single method that mutates an array in place to put nullable elements in options:

\regexSanitizerTypeClass

From a design standpoint, this solution is appealing as it leads to no duplicated code or computation: we perform our capturing group analysis at the type-level, once and for all, and synthesize code accordingly.
This combination of type-level programming and implicit-based code synthesis is reminiscent of multi-stage metaprogramming, in its com\-pile-time variant \citep{stucki2018practical}.
In those terms, our approach corresponds to a multi-staged program whose stage 0 happens entirely within Scala's type checker.

In the following section, we evaluate the performance of our library and discuss the trade-offs between the first and second implementation of our runtime component.

\section{Evaluation}
\label{sec:evaluation}

To assess the correctness of our library, we run our implementation against the QT3TS test suite \citep{w3c1994xquery}, which consists of about 1700 test cases for regular expressions \citep{w3c1994qt3ts}.
We select the subset of those tests that are positive and exercise capturing groups, totaling 183 test cases, which we then collated to form our benchmark suite.
We use these benchmarks to evaluate the performance of our library in terms of compilation times and execution times.

In \Cref{fig:regexBars}, we show the results of our experiments, which compare Scala's standard regular expression library (Std) against two flavors of our library, one using our code-dupli\-cated runtime (Dup), presented in \Cref{subsec:we-ain-t-need-no-dependent-types}, and the other using our implicit-based runtime (Impl), presented in \Cref{subsec:implicit-based-extractor-synthesis}.

\regexBars{A comparison of the compilation time (left) and execution time (right) of Scala's standard regex library (Std) against our library with its code-duplicated runtime (Dup) and with its implicit-based runtime (Impl).}

We obtained these results by averaging the measurements obtained over 2-hour runs, for each data point, which we executed on an i7-7700K Processor running Oracle JVM 1.8.0 and Linux.
With these settings, we obtain margins of errors below \textpm1\%, with 99.9\% confidence (omitted in \Cref{fig:regexBars}).
We run our benchmarks on the latest version of Scala~3 at the time of writing (3.1.2).

\paragraph{Compilation Times} Our library in its code-duplicated variant adds a total of 53~ms over the baseline's total compilation time (an average of +0.3~ms per regex).
This corresponds to the cost of match type reduction.
The implicit-based variant adds another 21~ms (+0.1~ms per regex), which corresponds to the cost of implicit resolution.
Both variants are thus relatively cheap, which validates their utility for practical uses.
When it comes to compilation times, it would be misleading to compare increments relative to the overall time, given that the compiler spends a large portion of its time outside of type checking \citep[§ 2.11.3]{petrashko2017design}.

\paragraph{Execution Times} At runtime, our code-duplicated variant adds 51~\textmu s over the baseline.
Although this difference is three orders of magnitude smaller than at compile-time, it corresponds to a 25\% increase, which is a rather substantial price to pay for redoing an already-performed analysis (|transform| redoes the analysis performed by |Compile|).
The implicit-based variant gets rid of this cost by synthesizing a type-specialized runtime (at the cost of increased compilation time).
To our surprise, our implicit-based runtime outperforms Scala's standard library implementation.
We suspect that this difference is due to the poor interaction between the JVM's just-in-time compiler and the code generated for variadic extractors (|unapplySeq|, used by the Std implementation).
Our implicit-based implementation appears to be more prone to inlining and partial evaluation since it does not involve generic sequences, which could explain the slight gain in performance.

\bigskip

In view of these results, we decided to use our implicit-based runtime in the published version of our library.

\section{Related Work}
\label{sec:related}

We found surprisingly little literature concerned with the safety of regular expression capturing groups.
In a recent survey paper on regular expression correctness, \citet{li2021ensuring} classified the publications in this area into several categories, ranging from empirical studies to regular expression synthesis and repair.
However, they only listed a single paper about static checking: the type system developed by \citet{spishak2012type} to validate regular expression syntax and capturing group usage in Java programs.
Their tool takes the form of a compiler plugin that enhances Java's type system to track the number of capturing groups using type annotations.
Unlike our system, their solution is not concerned with null safety and does not detect optional capturing groups.
In practice, their tool operates similarly to a linter: it reports false positives and sometimes requires manual annotations.

The Haskell ecosystem contains several packages for regular expressions, with various levels of static safety.
The regex-applicative package stands on the safe side of that spectrum: it allows programmers to write regular expressions using a parser combinator library, which entirely removes the need to reference capturing groups \citep{cheplyaka2011regex}.
The main drawback of this solution lies in the library's learning curve: programmers already familiar with POSIX regular expressions~\citep{ieee2018the} are forced to learn a new syntax, which is arguably more complicated.

Stephanie Weirich presented on several occasions a regular expression library as an example of a dependently-typed program written in Haskell \citep{weirich2014examples}.
The library provides safety guarantees similar to ours, but from the slightly different angle of named-capturing groups.
An important conceptual difference between the two approaches is that ours only focuses on type checking (we rely on Java's regular expressions at run-time), whereas hers also includes a fully-fledged regular expression engine.

The typed-regex~\citep{akshay2021typed} Typescript library provides a type-safe API for extracting named capturing groups of regular expressions.
The implementation uses conditional types \citep{microsoft2020typescript}, Typescript's type-level ternary operator, to statically analyze regular expressions.
Their approach, like ours, identifies optional capturing groups and marks them as such (using Typescript's optional properties).
At the time of writing, the library is still in the early stages of development and only supports a subset of the regular expression syntax, and notably lacks support for nested optional capturing group detection.

The safe-regex~\citep{leonhard2021safe} Rust library takes a different approach towards the same goal: it uses Rust macros to statically compile regular expressions and generate arity-specific extractors.
Performance-wise, macros improve over the status quo since they remove the need to compile regular expressions at runtime.
Safety-wise, code generation provides a straightforward solution to safe capturing group extraction.

\section{Conclusion}
\label{sec:conclusion}

In this \paper, we introduce a new design for type-safe regular expressions in Scala.
We presented our type-level analysis, which identifies capturing groups and computes their nullability.
We built our library following the design of the original Scala regular expression API, in order to provide a frictionless migration path for programmers interested in the additional type safety.
We evaluated our implementation by running it against the QT3TS test suite and showed that, on those benchmarks, our type-level analysis only has a marginal impact on compilation times.

\paragraph{Future Work}
We propose to extend our approach with a dedicated data type for the regex alternative operator.
In our current design, we map every capturing group to an |Option[String]|, which does not always accurately reflect the structure of regular expressions.
For instance, when confronted with \lstinline!"(A)(B)|(C)"!, our system represents this expression's capturing groups as a 3-tuple, |(Option[String],| |Option[String],| |Option[String])|. This representation fails to account for the fact that the first two groups have identical nullability status, and that this status is opposite to the nullability of the third group.
Instead, we could represent those capturing groups as |Either[(String,| |String),| |String]|, which is isomorphic to the structure of the regular expression.
