\input{headers.tex}

\begin{document}

\frontmatter
\input{title-page}
\setcounter{page}{0}

\chapter{Acknowledgements}
\lipsum[1-2]

\bigskip
\noindent\textit{Lausanne, \today}
\hfill Olivier Blanvillain

\cleardoublepage
\chapter*{Abstract}
\markboth{Abstract}{Abstract}
\addcontentsline{toc}{chapter}{Abstract (English/Français)}
\lipsum[1-2] % max 3499 characters
\begin{otherlanguage}{french}
\cleardoublepage
\chapter*{Résumé}
\markboth{Résumé}{Résumé}
\lipsum[1-2]
\end{otherlanguage}

\hypersetup{linkcolor=black}
\tableofcontents
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{List of Figures}
\listoffigures
\hypersetup{linkcolor=purplish}
\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%  Thesis Content  %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{chap:introduction}

In March 2017, our research group went on a ski retreat in the Swiss Alps.
After a full day of skiing on the Diablerets massif, we gathered for a lab dinner.
Denys Shabalin, who was working on Scala Native at the time~\citep{shabalin2020just}, started a conversation about manual memory management.
The discussion revolved around the following question: could a Rust-like ownership system be viable for Scala?
Denys' answer was clear: ownership is fundamentally at odds with the way Scala handles references, and without making deep changes to Scala's type system, the task was simply impossible.

The next day, I came up with a toy domain-specific language (DSL) that implements the basis of a linear type system using type-level programming.
Here is an example of a short program written in this DSL:

\memImplicitMain

\noindent
The type argument of |Context| is a type-level list of strings that corresponds to the memory regions allocated at each program point.
Methods of |Context| use type-level programming techniques to enforce the following properties:

\begin{enumerate}
  \item memory regions must be allocated (|malloc|) \emph{before} they are deallocated (|free|),
  \item all memory regions must be deallocated by the end of the program,
  \item dereferencing (|deref|) is only allowed on previously allocated regions.
\end{enumerate}

\noindent
The implementation makes use of Scala's implicits to enforce these properties.
While this small DSL is obviously too simplistic to be of any practical use, it demonstrates the power of type-level programming.

% 2. Identify the Research Gap
I was delighted with my solution!
Denys, however, was not impressed.
I attribute this apathy to his dislike of implicits.
Despite their widespread usage, implicits are notorious for their complexity~\citep{kvrikava2019scala}.
In particular, using implicits for type-level computations requires carefully crafted definitions following a specific pattern.
To give the reader a glimpse of this pattern, we show the definition of the |free| method on |Context|:

\memImplicitContextFree

\noindent
This definition uses three parameter lists, one for type parameters (|V| and |Out|), one for a value parameter (|v|), and one of an implicit value parameter (|ev|).
Only the second parameter list is intended to be specified at use site; the type and implicit parameters are meant to be inferred.
When a user writes |.free("mem")| he only sets the |v| parameter (|v="mem"|); the compiler takes care of finding valid assignments for |V|, |Out| and |ev|.
The implicit parameter of type |Remove[V,Ps,Out]| is the entry point to the world of type-level programming, it specifies how |V| (constrained by to be |v|'s type), |Ps| (defined in the class), and |Out| (unconstrained) are interrelated:

\memImplicitRemove

\noindent
Implicit-prefixed definitions can be understood as \emph{facts} and \emph{rules} of a logic program.
The first definition, |casehead|, specifies a fact: the result of removing |V| from the list |V::Ps| is |Ps|, which is expressed as an instance of |Remove[V,V::Ps,Ps]|.
The second definition, |casetail|, specifies a rule: if the result of removing |V| from the list |Pt| is |Out|, the results of removing |V| from the list |Ph::Pt| is |Ph::Out| (\Cref{sec:hlists-remove} develops this example in more details).
When a user writes |ctx.free("mem")| on a |ctx| of type |Context["bool"::"mem"::HNil]|, the compiler uses |casehead| and |casetail| to compute a type |Out| such that |Out| is the results of removing |"mem"| from |"bool"::"mem"::HNil|.

In retrospect, I have to agree with Denys' judgment at the time: this style of programming is convoluted, to say the least.
Aesthetics and pragmatism aside, programming with implicits requires a complete paradigm shift.
Instead of using pattern matching and functions, implicits require algorithms to be expressed using relations and constraints, which makes the task harder than it should be.

% 8. State Research Objectives
\emph{Can we do better?} This is the question that motivates the work presented in this dissertation.

% 3. State the Background Information
Dependently-typed programming languages, such as Coq~\citep{bertot2004interactive}, Agda~\citep{norell2007towards}, and Idris~\citep{brady2014idris}, make no distinction between terms and types, and thus naturally support type-level programming.
Scala, on the other hand, has a clear separation between its term and type language.

% When terms are types are unified, the distinction between programming and type-level programming blurs out since value-level computations can be performed during type checking.

TLP isn't new. GHC' Haskell is leading the charge with the numerous language extentions developped over the las decate. Unfortunately, many of the techniques developed in the context of Haskell are not directly applicable to other programming languages. In particular, subtying ...

% 9. Create an Outline
% - (Ab)Using Implicits
% - Generalizing Scala's Singleton Types
% - Match Types
% - Performance Evaluation

\lipsum[1]

\chapter{(Ab)Using Implicits}
\label{chap:ab-using-implicits}

Scala's implicit parameters have outgrown their roots as a simple syntactic construct to the extent that they provide basic support for type-level programming.
In this chapter, we present techniques for implicit-based type-level programming in Scala.
In particular, through extended examples, we show how to use Scala's implicit resolution mechanism to \emph{compute} types, in a style that resembles logic programming.

\subsection*{Attribution}

The first section of this chapter is based on the introduction to implicits from~\citep{odersky2018simplicitly}, which was written in collaboration with Martin Odersky, Fengyun Liu, Aggelos Biboudis, Heather Miller and Sandro Stucki, and published in POPL'18.

Code samples for the remaining of this chapter are based on the implementation of heterogeneous lists from the Shapeless library~\citep{sabin2011shapeless}.

\section{Implicit Parameters: Overview}

\emph{Implicit parameters} offer a convenient way to write code without the need to pass all arguments explicitly.
The ability to omit function arguments gives rise to many interesting coding styles and patterns.
On every call to functions with implicit parameters, the compiler looks for an implicit definition in scope to satisfy the call.
So, instead of passing a parameter explicitly:

\explicitModulo

\noindent
we can mark a set of parameters as implicit (a single parameter in this example) and let the compiler retrieve the missing argument for us.
In the following example, |addm| is a method with one implicit parameter and |modulo| is an implicit definition:

\implicitModulo

The process of implicit parameter discovery performed by the compiler is called \emph{implicit resolution}.
The resolution algorithm looks for implicits in the current scope and in the companion objects of all classes associated with the query type.
In the previous example, the implicit definition is declared in the current scope.
Since that definition has type |Int|, the compiler resolves the method call by passing |modulo| automatically.

\subsubsection{The type class pattern}

Implicits can be used to implement type classes~\citep{wadler1989how} as a design pattern~\citep{oliveira2010type}.
We give an example of an implementation of the |Ordering| type class.
This example consists of three parts:

\begin{enumerate}
  \item |Ordering[T]|, which is a regular trait with a single method, |compare|,
  \item the generic function |comp|, which compares two arguments and accepts an implicit argument, providing an \emph{implicit evidence} that these two values can be compared,
  \item the implicit definition |intOrdering|, which provides an \emph{instance} of the |Ordering| type class for integers.
\end{enumerate}

\ordExample

We have briefly introduced implicit parameters and showed how they can be used to avoid clutter in function applications.
In the next section, we present recursive implicit resolution.

\section{Recursive Implicit Resolution}

Implicit methods can themselves take implicit parameters.
For example, we can define the lexicographic list ordering as follows:

\ordListExample

\noindent
This definition is parametrized by the list's element type and by an ordering of that type, passed as an implicit parameter.
Since |listOrdering| is itself implicit, it defines a \emph{rule}: it allows the compiler to materialize an implicit |Ordering[List[T]]|, given an implicit |Ordering[T]| (for any type |T|).

Parametrized implicit definitions can lead to recursive implicit resolution. For example, the compiler will use |listOrdering| twice to synthesize an implicit |Ordering[List[List[T]]]|.
This is where the (type-level) fun begins!

\subsubsection{Heterogeneous lists}

A heterogeneous list, or |HList| for short~\citep{kiselyov2004strongly}, is a datatype capable of storing data of different types.
In Scala~3, we can define the |HList| datatype as follows:

\hlistEnumDefinition

\noindent
The |::| constructor offers an interesting symmetry between the term and type level, which allows |HList| types to capture the same structure that their term-level counterparts.
For example, the term |::(1,::(2,HNil()))| can be typed as |::[1,::[2,HNil]]|, which is a perfect reification of that term (we use literal singleton types to represent constant literals at the type level~\citep{leontiev2014sip}).

\subsubsection{HList's remove}
\label{sec:hlists-remove}

Scala's implicits allow us to define type-level operations for heterogeneous lists.
We develop the example presented in \Cref{chap:introduction} by looking into the remove operation on |HList|s.
Remove operation takes as argument an element and a list, and returns that list with the first occurrence of the element removed.
This operation should yield an error if the element is not part of the list.

An implicit-based type-level operation typically takes the form of a trait, the operation's entry point, and several implicit definitions, one for each "case" of the operation's algorithm.
Let us consider the implementation of the remove operation in more detail:

\memImplicitRemove

\noindent
The |Remove| trait takes 3 type parameters: 2 inputs, |V| (the element to remove) and |Ps| (the list), and one output, |Out| (the list, with the element removed).
The two implicit definitions, |casehead| and |casetail|, correspond to the base case and the recursive case of the list removal operation, respectively.
The |Remove| trait is intended to be used as an implicit parameter, with constrained input types, and an unconstrained output type.

When the given element is not part of the list, implicit resolution fails with an "implicit not found" error, which indicates the incorrect use of |Remove|.
More precisely, the implicit search first iterates through the list by repeatedly using |casetail| until it reaches the end of the list, at which point it fails to find an implicit value of type |Remove[V,HNil,Out]| (neither |casehead| nor |casetail| produce an instantiation of |Remove| with |Ps=HNil|).

As an example usage of |Remove|, consider the following stringly-typed, JavaScript-inspired method:

\addEventListenerJS

\noindent
This method's documentation specifies 5 valid alternatives for the |event| argument, but that constraint is not reflected in the method's type signature.
In JavaScript, calling this method with an erroneous element event type is a \emph{no-op}, which can make this kind of error particularly hard to spot.

Instead of specifying that constraint in the documentation, we can represent the valid event types in a |HList|, and use an implicit parameter of type |Remove| to statically enforce that property:

\addEventListenerImplicitDef

\noindent
The |Singleton| type bound is a marker that instructs type inference to preserve literal singleton types (by default, the compiler widens those types).
The "|?|" type is Scala~3's new syntax for wildcard types~\citep[Wildcard Arguments in Types]{odersky2013scala}.

With this updated signature, the compiler is able to detect invalid event types at compile time.
When given a valid event type |E|, the compiler synthesizes an implicit evidence of type |Remove[E,EventTypes,?]| which witnesses |E|'s validity.
After implicit resolution, calls to the |addEventListener| method are expanded to automatically insert an implicit parameter for the second parameter list, such as in the following example:

\addEventListenerImplicitCall

This concludes our presentation of the implicit-based encoding of type-level computation.
Despite its verbosity, this pattern generalizes to arbitrary recursive computations and enables Scala programmers to write elaborate type-level programs solely based on implicits.
In the next section, we discuss ambiguities and priorities between implicit definitions.

\section{Ambiguities and Priorities}

Scala's implicit resolution relies on an intricate priority system to establish the precedence of implicit definitions.
Implicit-based programs sometimes rely on ambiguities and priorities of implicit definition, as we will see in this section through a series of example.

\subsection{Implicit Ambiguities}

The Scala compiler rejects programs with \emph{ambiguous} implicit definition.
For instance, if we write two identically-typed implicit definitions in the same scope, the compiler will consider them ambiguous and report an error:

\implicitAmbiguity

While ambiguities typically indicate programming errors, we can also use them purposefully to implement the error case of a type-level program.
As an example, consider the |NotIn| operation on |HList| that is only defined if the given element is \emph{not} part of the list.
We define |NotIn| using two ambiguous implicits; the implementation is lengthy, but straightforward:

\memImplicitNotIn

\noindent
The |casenil| and |casecons| implicits simply iterate through the list.
The |ambiguous| implicits are two identical definitions that will cause the compiler to raise an error if |V| and |Ph| are equal, for any element |Ph| of the list ("|=:=|" is a type from Scala's standard library that witnesses mutual subtyping).

As an example usage of |NotIn|, we revisit the DSL presented in \Cref{chap:introduction}.
Programs in our DSL consist of sequences of method calls on a |Context|, which tracks the memory regions that are currently allocated in the program, using a |HList| of names.
We use the |NotIn| operation to constrain the allocation method, |malloc|, to prevent allocating regions with already used names:

\memImplicitContextMalloc

Scala~3 introduced an alternative to the ambiguous implicit pattern in the form of the |scala.util.NotGiven| type~\citep[Given Instances]{odersky2013scala}.
The compiler will synthesize an implicit parameter of type |NotGiven[T]|, if and only if there is no implicit value of type |T| in scope.
We can use a "negative" implicit evidence to simplify the definition of |NotIn| by removing the ambiguous implicits and changing |casecons| to the following:

\memImplicitNotGiven

\subsection{Implicit Priorities}

When looking for implicits, the Scala compiler visits scopes sequentially, in a precisely defined order.
At any point in the search, if the implicits defined in the subset of scopes considered so far can fulfill the implicit query, the search succeeds and immediately terminates.
This incremental process has two consequences.
First, it allows the compiler to efficiently look for implicits by naturally pruning some of the search space.
Second, it provides an ad-hoc mechanism to disambiguate implicits.
Scala programmer can artificially partition their implicit definitions into multiple scopes to implement a priority system.

Let us consider an example of operation on |HList| whose implementation uses implicit priorities.
|RemoveAll| is a generalization of |Remove| that removes every occurrence of the given element instead of the first occurrence.
The implicit-based implementation takes the form of a trait with 3 type parameters: 2 inputs, |V| (the element to remove) and |Ps| (the list), and one output, |Out| (the list, with the elements removed):

\removeAllDefinition

From an algorithmic standpoint, we can implement |RemoveAll| as a recursive function with 3 cases, a base case for the empty list (|casenil|), a recursive case for when the head of the list matches the element to remove (|casematch|), and another recursive case for when the head doesn't match (|casedoesnt|):

\removeAllBroken

This direct implementation of |RemoveAll| using implicit definitions is, unfortunately, incorrect.
The issue is that the |casematch| and |casedoesnt| definitions are ambiguous when the head of the list matches the element to remove.
To work around that ambiguity, we split those definitions into two different scopes, so that the compiler always tries to apply the more specialized case (|casematch|) before considering the less specialized case (|casedoesnt|).
Concretely, we define low priority implicits in a separate trait, and have |RemoveAll|'s companion object extend that trait:

\removeAllPrioritized

\section{Conclusion}

In this chapter, we presented several techniques for type-level programming with implicits.
This style of programming is, unfortunately, quite cumbersome.
In addition to the heavy syntax, type-level programming with implicits also requires a deep understanding of the implicit resolution algorithm.
As we will see in \Cref{chap:performance-evaluation}, those techniques come at a high cost in terms of compilation time, which hinders their usability on a large scale.
Yet, despite those shortcomings, Scala programmers have shown a persistent interest in this style of programming, as demonstrated by its popularity in the open-source community~\citep{sabin2011shapeless, pilquist2013scodecs, blanvillain2016frameless}.

\chapter{Generalizing Scala's Singleton Types}
\label{chap:generalizing-scala-s-singleton-types}

Type-level programming is an increasingly popular way to obtain additional type safety.
Unfortunately, it remains a second-class citizen in the majority of industrially-used programming languages.
We propose a new dependently-typed system with subtyping and singleton types whose goal is enabling type-level programming in an accessible style.
To this end, we have prototyped our system as an extension of the Scala programming language.
We demonstrate the practicality of our system with a case study in which we develop a strongly-typed wrapper for Spark datasets.
Through our formalization and implementation in the context of an industrial-strength compiler, we hope to provide valuable insights for language designers interested in dependent types.

\subsection*{Attribution}

This chapter is based on~\citep{schmid2020coming}, which was written in collaboration with Georg Schmid, Jad Hamza, and Viktor Kuncak.
Georg and I worked hand-in-hand on this project: we collaborated through countless whiteboard discussions and pair programming sessions, which resulted in shared first authorship of the implementation and most of the text.
The said report covers more material than what is included in this chapter, in particular, our formalization and the associated metatheory are out of the scope of this dissertation.

\input{preprint.tex}

\chapter{Match Types}
\label{chap:match-types}

Type-level programming is becoming more and more popular in the realm of functional programming.
However, the combination of type-level programming and subtyping remains largely unexplored in practical programming languages.
This chapter presents \emph{match types}, a type-level equivalent of pattern matching.
Match types integrate seamlessly into programming languages with subtyping and, despite their simplicity, offer significant additional expressiveness.
We formalize the feature of match types in a calculus based on \SystemFsub and prove its soundness.
We practically evaluate our system by implementing match types in the Scala~3 reference compiler, thus making type-level programming readily available to a broad audience of programmers.

\subsection*{Attribution}

This chapter is based on~\citep{blanvillain2022type}, which was written in collaboration with Jonathan Brachthäuser, Maxime Kjaer, and Martin Odersky, and published in POPL'22. \Cref{sec:case-study-shape-safe-num-py} is based on Maxime's semester project entitled "Shape-safe TensorFlow in Dotty", where he designed a strongly typed TensorFlow interface in Scala, which checks tensor shapes at compile-time in order to prevent runtime errors in machine learning models. Maxime also contributed to the Scala~3 compiler by adding support for arithmetic computations at the type level. Jonathan mechanized the soundness proof for \SystemFm, and provided invaluable help and guidance with redaction. Martin and I collaborated on the implementation of match types in the Scala 3 compiler, which is now actively used by the Scala community.

\input{article.tex}

\chapter{Performance Evaluation}
\label{chap:performance-evaluation}

In this chapter, we report performance evaluation results for the various type-level programming techniques introduce in prior chapters.
Specifically, we are interested in evaluating the scalability of each technique when confronted with large type-level programs, in terms of compilation times (\Cref{sec:compilation-time}) and binary sizes (\Cref{sec:binary-size}).
In \Cref{sec:the-timing-of-match-type-reductions}, we discuss how the timing of match type reduction impacts compilation times.

\section{Method}

We evaluate the performance of the 3 type-level programming techniques presented in this dissertation by comparing them on a set of 4 benchmarks.
Each benchmark consists of a simple type-level operation, which we implemented once using implicits (\Cref{chap:ab-using-implicits}), once using generalized singletons (\Cref{chap:generalizing-scala-s-singleton-types}), and once using match types (\Cref{chap:match-types}).

These benchmarks are inspired by code examples used throughout this dissertation. They all follow a similar pattern of a single function call whose result type is computed at the type level. We code generated variations of each benchmark with increasing input size, from 1 to 256, in increments of 8.
The source code of our benchmarks is available in the supplementary material of this dissertation\footnote{\texttt{https://olivierblanvillain.github.io/thesis/benchmarks.zip}}, alongside instructions on how to reproduce our experiments.

Here is a brief description of our benchmark suite:

\begin{enumerate}
  \item \textbf{Concat}\quad
  Concatenates a heterogeneous list with itself.

  \item \textbf{Remove}\quad
  Removes the last element of a heterogeneous list (\Cref{sec:hlists-remove}).

  \item \textbf{Join}\quad
  Computes the resulting schema after performing a self-join along the last column of a database table (\Cref{sec:safe-join}).

  \item \textbf{Reduce}\quad
  Computes the dimension of a multidimensional array after dimensional reduction along all axes (\Cref{subsubsec:reduction}).
\end{enumerate}

We run the experiments presented in this chapter on an i7-7700K processor running OpenJDK~1.8.0\_212 and Linux.
For the implicit and match type benchmarks, we use the latest Scala~3 release (version~3.1.2 at the time of writing).
For the generalized singleton benchmarks, we use our prototype implementation, which lives in a branch of the dotty-staging repository\footnote{\texttt{git clone git@github.com:dotty-staging/dotty.git --branch add-transparent-7}}.

\section{Compilation time}
\label{sec:compilation-time}

\timingGraphsZoomedOut{A comparison of the compilation time of implicits, generalized singletons and match types for our benchmark suite (lower is better).}

\Cref{fig:timingGraphsZoomedOut} compares the compilation time of implicits, generalized singletons and match types on our benchmark suite.
The compilation time of implicit-based benchmarks dominates the graphs on each figures, and suggests a quadratic complexity.
These results imply that implicits are ill-suited for large scale type-level computations: spending tens of seconds on a single operation is clearly out of the question for practical applications.

\timingGraphsZoomedIn{A comparison of the compilation time of generalized singletons and match types for our benchmark suite (lower is better).}

The same measurements are shown in \Cref{fig:timingGraphsZoomedIn}, but with millisecond y-axes, to focus on the comparison of non-implicit curves.
Each graph follows a similar trend, with singleton-based implementations outperforming their match-type-based counterparts by about a factor of two.
We speculate that this difference is due to the overhead of subtyping, which in inherent to the design of match type.
Our prototype for generalized singletons uses a dedicated type evaluation procedure that is specialized for the task and thus faster.

We obtained the data points of \Cref{fig:timingGraphsZoomedOut} and~\ref{fig:timingGraphsZoomedIn} using Java Microbenchmark Harness (JMH) with 60 seconds of warmup, 60 seconds of measurement and a single JVM fork.
As a result, the resulting measurements are precise (99.9\% confidence intervals vary between $\pm$ 0.5 and $\pm$ 2 milliseconds), but subject to variations caused by the unpredictability of the JVM's just in time compiler, which explains the bumps visible in \Cref{fig:timingGraphsZoomedIn}.

\section{Binary size}
\label{sec:binary-size}

\bytecodeSizeTable{Additional JVM Bytecode generated per input size increment (in bytes).}

In \Cref{fig:bytecodeSizeTable}, we show the amount of additional JVM Bytecode generated per benchmark size increment.
The binary sizes of singleton- and match-type-based implementations are stable with respect to benchmark input size, which is expected given that our benchmarks consist of type-level-only operations.

The binary sizes of implicit-based implementations grow linearly with the input size, by 6 bytes per input size increment for smaller benchmarks (Concat and Remove), and by 12 and 18 bytes for the larger benchmarks (Reduce and Join, respectively).
To put those numbers in perspective, they represent an overall binary size increase of 9\%, 9\%, 12\%, and 20\%, when comparing the size-1 instantiation to the size-256 instantiation of Concat, Remove, Reduce, and Join, respectively.
These increases in binary size are caused by the implicit evidences synthesized by the compiler during implicit resolution.
In our benchmarks, those evidences have no runtime purpose and are simply an artifact of the mechanism in play.
Other applications, such as those supported by the Shapeless library~\citep{sabin2011shapeless}, take advantage of implicit evidence synthesis to provide additional runtime functionalities.

\section{The Timing of Match Type Reductions}
\label{sec:the-timing-of-match-type-reductions}

In \Cref{chap:match-types}, we describe the match type reduction algorithm by adding new subtyping rules to \SystemFsub (\Cref{subsec:matches}).
The resulting system is entirely declarative: it doesn't specify \emph{when} to apply those rules.
In this section, we discuss how the timing of match type reduction impacts compilation times.

A correct type system implementation must attempt to reduce match types \emph{as late as possible}, during subtyping.
Indeed, failing to do so could lead to incorrect results in cases where a match type is reducible in the context of the subtyping query but is not reducible in any prior context.

In addition to the reductions attempted during subtyping, the compiler can try to reduce match types earlier in the pipeline, essentially at any point in time.
Doing so is always correct, since the types before and after reduction are mutually subtypes of each other.
Each early attempt of match type reduction is a trade-off: it can either be a small overhead, if the reduction fails, a no-op, if the reduction succeeds but the result is used exactly once, or an optimization, if the reduction succeeds and the result is used more than once.
Note that reducing match types in a lazy fashion would not be a replacement for early reduction attempts, because the subtyping and disjointness checks are context-dependent (\Cref{subsec:caching}).

Let us consider an example that illustrates the benefits of early reduction attempts:

\geqDefinition

\noindent
Without any early reductions, this definition will result in a quadratic number of additions. For example, here is the sequence of subtyping queries issued while compiling |GEQ[5,1]|:

\geqExample

\noindent
The first instance of |1+1| comes from the right-hand-side of the first |GEQ| call (with |B=1|), but that type is used in all the subsequent subtyping queries. As a result, reducing |1+1| to |2| once and for all leads to a speed-up in compilation.

Our Scala~3 implementation reduces match types at multiple points during compilation, including right after creating types, during subtyping, and after instantiating parameters of type applications.
This last point is essential to avoid the quadratic behavior of the |GEQ| example.
In \Cref{fig:timingGraphsTooEarlyTooLate}, we show the impact of this optimization on our Reduce benchmark.
In this figure, we compare the compilation times of the match type Reduce benchmark with (S1) and without (S2) the reduction of match types after type parameter instantiation.

\timingGraphsTooEarlyTooLate{A comparison of the compilation time of the match type Reduce benchmark with two different match type reduction strategies. S1 is the reduction strategy we implemented in the Scala~3 compiler. S2 is a variation of that strategy where we disabled the reduction of match types after type parameter instantiation.}

\chapter{Conclusion}
\label{chap:conclusion}
\lipsum[1]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Bibliography, Appendix, CV  %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\chapter{Type Soundness for System FM}
\renewenvironment{proof}{{\it Proof: }}{\qed} % Show proofs
\input{proofs/permutation.tex}
\input{proofs/weakening.tex}
\input{proofs/strengthening.tex}
\input{proofs/substitution.tex}
\input{proofs/disjointness-subtyping-exclusivity.tex}

\harpoonx{Definition of the auxiliary relation $\protect \⇌$, used to state inversion of subtyping.}

\begin{definition*}
  $\Γ \⊢ \S \⇌ \T$ (defined in \Cref{fig:harpoon}) represents evidence of the mutual subtyping between a match type $\S$ and a type $\T$ with the additional constraint that this evidence was exclusively constructed using pairwise applications of \emph{\SMatch1/2}, \emph{\SMatch3/4}, and \emph{\STrans} in both directions.
\end{definition*}

\input{proofs/inversion-of-subtyping.tex}
\input{proofs/canonical-forms.tex}
\input{proofs/inversion-of-typing.tex}
\input{proofs/minimum-types.tex}
\input{proofs/preservation.tex}
\input{proofs/progress.tex}

\backmatter
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{apalik}
\bibliography{bibliography}

\cleardoublepage
\thispagestyle{empty}
\phantomsection
\addcontentsline{toc}{chapter}{Curriculum Vitae}
\includepdf{olivier-blanvillain-resume.pdf}
\thispagestyle{empty}~

\end{document}
